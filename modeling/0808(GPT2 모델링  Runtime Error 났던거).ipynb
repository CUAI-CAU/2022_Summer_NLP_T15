{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20220808(GPT2 모델링  mark2 test_size 0.2 -> 0.25로 조정).ipynb","provenance":[{"file_id":"1itzUVL6GbRXeiPG2OrTIxeteFs9qZrCP","timestamp":1660025388628},{"file_id":"1CzsV3fwJR9HG34gKHmenhHN-FbZeKsNg","timestamp":1659595140610},{"file_id":"1DSzQOZ2TAdA-qNrp_3awAgU7mWtsFvRY","timestamp":1659509662271},{"file_id":"1RFHuFj6RR08vxkxNrR8-FTwkP9Zm9FM5","timestamp":1659003324943}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## 0. 구글 드라이브 연결 및 필수 라이브러리 설치 및 로드"],"metadata":{"id":"2kssQGB5iToK"}},{"cell_type":"markdown","source":["### 구글 드라이브 연결"],"metadata":{"id":"dt51lRmEzT4D"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07aeCwO3iTbc","executionInfo":{"status":"ok","timestamp":1660108735926,"user_tz":-540,"elapsed":18004,"user":{"displayName":"이강민","userId":"04405449783523250799"}},"outputId":"e8774a9b-25ac-48a4-aa60-080b4955034a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["### 필수 라이브러리 설치 및 로드"],"metadata":{"id":"gjjX5duczWCV"}},{"cell_type":"code","source":["#!pip install nltk"],"metadata":{"id":"MIoFlaitQuS_","executionInfo":{"status":"ok","timestamp":1660108735927,"user_tz":-540,"elapsed":10,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#!pip install konlpy"],"metadata":{"id":"ly6O3vlRH93D","executionInfo":{"status":"ok","timestamp":1660108735927,"user_tz":-540,"elapsed":8,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#from konlpy.tag import Okt\n","from tqdm import tqdm\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","#import nltk\n","import re\n","\n","from keras.callbacks import *\n","import os\n","import tensorflow as tf"],"metadata":{"id":"g35dYsbyH7k8","executionInfo":{"status":"ok","timestamp":1660108738791,"user_tz":-540,"elapsed":2871,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#nltk.download()\n","\n","# 이거 안하면 lookuperror 뜬다.(필요한 것만 지정해서 다운로드 해도되고, all을 사용하여 모두 다운로드 해도 된다.)"],"metadata":{"id":"Mw1S6BjNRZqn","executionInfo":{"status":"ok","timestamp":1660108738792,"user_tz":-540,"elapsed":11,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 이후에 데이터 및 파일들을 저장할 경로를 path로 통일하여 따로 저장\n","\n","path = '/content/gdrive/MyDrive/Colab Notebooks/CUAI 하계프로젝트-NLP/초기 모델링 진행/data/'"],"metadata":{"id":"hMgs4OigdbWe","executionInfo":{"status":"ok","timestamp":1660108738792,"user_tz":-540,"elapsed":9,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["***여기 이후부터는 완료된 단계(4. 토큰화, 5. 정수 인코딩 등)로 점프해서 실행시키면 됨!!(노트북을 나누면서 앞부분 삭제함)***"],"metadata":{"id":"kGn6QmC1c61X"}},{"cell_type":"markdown","source":["## 6. GPT2 모델링"],"metadata":{"id":"Pq73212r69Dv"}},{"cell_type":"markdown","source":["### 6-1. GPT2 모델링에 필요한 모듈 및 함수 import  "],"metadata":{"id":"k9UP-iC5WQma"}},{"cell_type":"markdown","source":["앞선 단계에서 토큰화, 정수 인코딩, 패딩, 워드 임베딩을 수행했으나   \n","GPT2 모델링에 참고한 책 **\"텐서플로 2와 머신러닝으로 시작하는 자연어 처리\"**를 보니(p.516) 기존에 한 것과 아예 다른 토크나이저를 사용하기 때문에 모델의 입력 데이터를 구성하는 방식이 다르다고 함  \n","따라서 책에 있는 코드를 따라가며 GPT2 모델링에 필요한 모듈 및 함수 import하였음"],"metadata":{"id":"BtKFRnW-ljM5"}},{"cell_type":"code","source":["!pip install gluonnlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gj8n-eS1p9zO","executionInfo":{"status":"ok","timestamp":1660108746264,"user_tz":-540,"elapsed":7479,"user":{"displayName":"이강민","userId":"04405449783523250799"}},"outputId":"a703fa70-c253-42f1-fc54-59f0635de2f5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595734 sha256=42e1483808d04a7ee7d87eb6b83a2b77b3fae5b6dc342cec49811a1dfad96fbd\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n"]}]},{"cell_type":"code","source":["!pip install mxnet "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-6-VRoOqDzR","executionInfo":{"status":"ok","timestamp":1660108755287,"user_tz":-540,"elapsed":9029,"user":{"displayName":"이강민","userId":"04405449783523250799"}},"outputId":"cb189e53-1d8a-4699-a39f-0c30b4b664f3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[K     |████████████████████████████████| 49.1 MB 161 kB/s \n","\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JtIgB9C0qWWG","executionInfo":{"status":"ok","timestamp":1660108763242,"user_tz":-540,"elapsed":7971,"user":{"displayName":"이강민","userId":"04405449783523250799"}},"outputId":"3f32cee3-0328-4bff-851d-d30773dd900c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 11.7 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 59.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 48.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","source":["# 모델 학습에 필요한 3개의 모듈 import\n","\n","import gluonnlp as nlp\n","from gluonnlp.data import SentencepieceTokenizer\n","from transformers import *"],"metadata":{"id":"FCnSb8Kf-LA-","executionInfo":{"status":"ok","timestamp":1660108772174,"user_tz":-540,"elapsed":8952,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# 불러온 모델을 활용해 여기서 사용할 모델 클래스를 구현\n","class GPT2Model(tf.keras.Model):\n","    def __init__(self, dir_path):\n","        super(GPT2Model, self).__init__()\n","        self.gpt2 = TFGPT2LMHeadModel.from_pretrained(dir_path)\n","\n","    def call(self, inputs):\n","        return self.gpt2(inputs)[0]"],"metadata":{"id":"YYNyQ-V5-K7Z","executionInfo":{"status":"ok","timestamp":1660108772175,"user_tz":-540,"elapsed":8,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["! pip install wget"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFOsWfzHsQNk","executionInfo":{"status":"ok","timestamp":1660108776488,"user_tz":-540,"elapsed":4319,"user":{"displayName":"이강민","userId":"04405449783523250799"}},"outputId":"dc816fe4-0b59-4b1a-af03-bce0627f0ddb"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=64626793b54f74f8348b96c4b9d946dc29ce686615d9b24e40eb36da9cf3df4b\n","  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"]}]},{"cell_type":"code","source":["# 구현된 모델 클래스에 학습된 파라미터를 다운로드\n","import wget\n","import zipfile\n","\n","wget.download('https://github.com/NLP-kr/tensorflow-ml-nlp-tf2/releases/download/v1.0/gpt_ckpt.zip')\n","with zipfile.ZipFile('gpt_ckpt.zip') as z:\n","    z.extractall()"],"metadata":{"id":"Zz8cYJxgrhI1","executionInfo":{"status":"ok","timestamp":1660108790971,"user_tz":-540,"elapsed":14499,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# 학습된 파라미터를 다운로드 받았다면 다음과 같은 경로로 파라미터를 이동시킨 후 모델을 선언\n","# 경로에는 반드시 config.json과 tf.model.h5 파일이 있어야 함\n","BASE_MODEL_PATH = './gpt_ckpt'\n","gpt_model = GPT2Model(BASE_MODEL_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Esu7V63zsOUr","executionInfo":{"status":"ok","timestamp":1660108795215,"user_tz":-540,"elapsed":4255,"user":{"displayName":"이강민","userId":"04405449783523250799"}},"outputId":"5005a7e1-292e-47c4-ea21-9c5fec33e4df"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file ./gpt_ckpt/config.json\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.21.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50000\n","}\n","\n","loading weights file ./gpt_ckpt/tf_model.h5\n","All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n","\n","All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ./gpt_ckpt.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"]}]},{"cell_type":"markdown","source":["### 6-2. final_data를 train/test로 나눈 후 train 데이터 전처리"],"metadata":{"id":"z6Rdy9r6tsTO"}},{"cell_type":"code","source":["# 후에 나올 주요 변수들 정의\n","MAX_LEN = 25 # okt 형태소 분석기로 분석했을 때 95%의 데이터들이 살아남은 지점의 길이\n","NUM_EPOCHS = 3 # 임의로 설정\n","BATCH_SIZE = 64 # 임의로 설정\n","VALID_SPLIT = 0.1 # 임의로 설정"],"metadata":{"id":"zqEzOw9SWQLY","executionInfo":{"status":"ok","timestamp":1660108795217,"user_tz":-540,"elapsed":10,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SghLKQaAu6Kp","executionInfo":{"status":"ok","timestamp":1660108799220,"user_tz":-540,"elapsed":4012,"user":{"displayName":"이강민","userId":"04405449783523250799"}},"outputId":"cc00107a-96ea-4ea2-a448-3517ccf6e940"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 4.9 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["# 데이터를 불러오기에 앞서 먼저 토크나이저를 생성\n","TOKENIZER_PATH = './gpt_ckpt/gpt2_kor_tokenizer.spiece'\n","tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)\n","vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH, \n","                                               mask_token=None, \n","                                               sep_token='<unused0>', \n","                                               cls_token=None, \n","                                               unknown_token='<unk>',  \n","                                               padding_token='<pad>', \n","                                               bos_token='<s>', \n","                                               eos_token='</s>')"],"metadata":{"id":"UoSAFKGWtBxG","executionInfo":{"status":"ok","timestamp":1660108799615,"user_tz":-540,"elapsed":410,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["|스페셜 토큰|역할|\n","|-------|--------|\n","| unused0 |SEP 토큰으로 두 개의 문장을 입력할 때 문장을 구분해 주는 토큰으로 활용  \n","||(자연어 추론과 텍스트 유사도 모델에서 활용 예정)|"],"metadata":{"id":"wkjFh8i1u_6W"}},{"cell_type":"code","source":["# 이제 final_data 로드\n","# (참고)path 부분은 맨 앞 0장의 마지막 코드에서 경로 지정하였음!\n","\n","data = pd.read_excel(path + 'final_data.xlsx', engine='openpyxl')"],"metadata":{"id":"5rFcqlqyWQBR","executionInfo":{"status":"ok","timestamp":1660108822312,"user_tz":-540,"elapsed":22702,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["data.tail(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"6EvyQZMRW8II","executionInfo":{"status":"ok","timestamp":1660108822313,"user_tz":-540,"elapsed":30,"user":{"displayName":"이강민","userId":"04405449783523250799"}},"outputId":"4419227c-eda1-4bf0-9135-73ef0f36e464"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Unnamed: 0                       document  label\n","303472      303472       당장 내일 밥은 어떡하고 내 병원비는 어쩌지      0\n","303473      303473  응 이제 다들 독립해가지고 명절 아니면 찾아오질 않아      0\n","303474      303474               안부전화라도 해주면 좋을 텐데      0"],"text/html":["\n","  <div id=\"df-b2e649f2-56c1-4d79-8275-e4429ced4e28\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>303472</th>\n","      <td>303472</td>\n","      <td>당장 내일 밥은 어떡하고 내 병원비는 어쩌지</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>303473</th>\n","      <td>303473</td>\n","      <td>응 이제 다들 독립해가지고 명절 아니면 찾아오질 않아</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>303474</th>\n","      <td>303474</td>\n","      <td>안부전화라도 해주면 좋을 텐데</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2e649f2-56c1-4d79-8275-e4429ced4e28')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b2e649f2-56c1-4d79-8275-e4429ced4e28 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b2e649f2-56c1-4d79-8275-e4429ced4e28');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# 책에 train과 test 데이터를 나눴으므로 train_test_split을 이용해 final_data를 분리(랜덤 시드 42로 고정)\n","X_train, X_test, y_train, y_test = train_test_split(data['document'],data['label'], \n","                                                    test_size = 0.2, stratify = data['label'], random_state=42)"],"metadata":{"id":"n3gQJ_cRt6Oo","executionInfo":{"status":"ok","timestamp":1660109095964,"user_tz":-540,"elapsed":306,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# 다시 train과 test끼리 묶어주고 이것을 일단 txt 파일로 저장\n","train_data = pd.concat([X_train, y_train], axis=1)\n","test_data = pd.concat([X_test, y_test], axis=1)\n","\n","train_data.to_csv(path + 'final_train_data.txt', sep = '\\t', index = False)\n","test_data.to_csv(path + 'final_test_data.txt', sep = '\\t', index = False)"],"metadata":{"id":"3xq2K81nt6Lm","executionInfo":{"status":"ok","timestamp":1660109099457,"user_tz":-540,"elapsed":1348,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# 이제 train 데이터로 토크나이저를 활용해 모델에 입력할 데이터를 구성\n","train_data_sents = []\n","train_data_labels = []\n","\n","def clean_text(sent):\n","    sent_clean = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", sent)\n","    return sent_clean\n","\n","for train_sent, train_label in train_data[['document', 'label']].values:\n","    train_tokenized_text = vocab[tokenizer(clean_text(train_sent))] \n","    # 위 코드 우측 부분이 책에는 clean_text(train_sent)로 되어있었으나 검색해보니\n","    # clean_text가 불필요한 문자 제거 그런거여서 이미 정제된 상태이므로 그냥 train_sent로 작성함\n","\n","    tokens = [vocab[vocab.bos_token]]\n","    tokens += pad_sequences([train_tokenized_text], \n","                            maxlen=MAX_LEN, # 앞에 6-2에서 임의로 정함\n","                            value=vocab[vocab.padding_token], \n","                            padding='post').tolist()[0]\n","    tokens += [vocab[vocab.eos_token]]\n","\n","    train_data_sents.append(tokens)\n","    train_data_labels.append(train_label)\n","\n","#train_data_sents = np.array(train_data_sents, dtype=np.int64)\n","#train_data_labels = np.array(train_data_labels, dtype=np.int64)"],"metadata":{"id":"RXmysT1kt6Iw","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"error","timestamp":1660109102110,"user_tz":-540,"elapsed":311,"user":{"displayName":"이강민","userId":"04405449783523250799"}},"outputId":"528426c6-f571-4fd8-a87d-d8d65dac2ade"},"execution_count":26,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-a194abfed600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_tokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 위 코드 우측 부분이 책에는 clean_text(train_sent)로 되어있었으나 검색해보니\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# clean_text가 불필요한 문자 제거 그런거여서 이미 정제된 상태이므로 그냥 train_sent로 작성함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gluonnlp/data/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \"\"\"\n\u001b[1;32m    560\u001b[0m         return self._processor.SampleEncodeAsPieces(sample, self._nbest,\n\u001b[0;32m--> 561\u001b[0;31m                                                     self._alpha)\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mSampleEncodeAsPieces\u001b[0;34m(self, input, nbest_size, alpha, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mSampleEncodeAsPieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m       return self.Encode(input=input, nbest_size=nbest_size, alpha=alpha,\n\u001b[0;32m--> 562\u001b[0;31m                          out_type=str, enable_sampling=True, **kwargs)\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mEncode\u001b[0;34m(self, input, out_type, add_bos, add_eos, reverse, emit_unk_piece, enable_sampling, nbest_size, alpha, num_threads)\u001b[0m\n\u001b[1;32m    502\u001b[0m                                       nbest_size == 1 or alpha is None):\n\u001b[1;32m    503\u001b[0m         raise RuntimeError(\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0;34m'When enable_sampling is True, We must specify \"nbest_size > 1\" or \"nbest_size = -1\", '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;34m'and \"alpha\". \"nbest_size\" is enabled only on unigram mode ignored in BPE-dropout. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;34m'when \"nbest_size = -1\" , this method samples from all candidates on the lattice '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: When enable_sampling is True, We must specify \"nbest_size > 1\" or \"nbest_size = -1\", and \"alpha\". \"nbest_size\" is enabled only on unigram mode ignored in BPE-dropout. when \"nbest_size = -1\" , this method samples from all candidates on the lattice instead of nbest segmentations."]}]},{"cell_type":"code","source":["# 원래는 위 코드 마지막에 이 부분이 같이 있었는데 계속 오류나서 따로 떼어옴\n","# 위 코드에서 maxlen을 특정 숫자(일단 28, 이전 단계에서 길이 28로 패딩한 것이 생각나서)\n","# 로 하니 np.array로 드디어 변환됨(단, 그때 패딩과 이때 패딩이 동일한 것인지는 확실x)\n","train_data_sents = np.array(train_data_sents, dtype=np.int64)\n","train_data_labels = np.array(train_data_labels, dtype=np.int64)"],"metadata":{"id":"CLr1cVrI-WLl","executionInfo":{"status":"aborted","timestamp":1660108824708,"user_tz":-540,"elapsed":419,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6-3. final_train_data를 모델에 학습시키기"],"metadata":{"id":"AslnGvWO_Y15"}},{"cell_type":"markdown","source":["민기가 사용했다는 gpu 추가 사용하는 거 코드 추가함"],"metadata":{"id":"XdW6AQp1Tm2X"}},{"cell_type":"code","source":["# GPU를 사용한 TensorFlow로 GPU 디바이스 확인\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"FsaNlqIZTugh","executionInfo":{"status":"aborted","timestamp":1660108824710,"user_tz":-540,"elapsed":421,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Observe TensorFlow speedup on GPU relative to CPU\n","import tensorflow as tf\n","import timeit\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print(\n","      '\\n\\nThis error most likely means that this notebook is not '\n","      'configured to use a GPU.  Change this in Notebook Settings via the '\n","      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n","  raise SystemError('GPU device not found')\n","\n","def cpu():\n","  with tf.device('/cpu:0'):\n","    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n","    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n","    return tf.math.reduce_sum(net_cpu)\n","\n","def gpu():\n","  with tf.device('/device:GPU:0'):\n","    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n","    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n","    return tf.math.reduce_sum(net_gpu)\n","  \n","# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n","cpu()\n","gpu()\n","\n","# Run the op several times.\n","print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n","      '(batch x height x width x channel). Sum of ten runs.')\n","print('CPU (s):')\n","cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n","print(cpu_time)\n","print('GPU (s):')\n","gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n","print(gpu_time)\n","print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"],"metadata":{"id":"G38IOudvXL-s","executionInfo":{"status":"aborted","timestamp":1660108824711,"user_tz":-540,"elapsed":422,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 학습에 앞서 GPT2 텍스트 분류기를 만들기 위해 TFGPT2Classifier라는 클래스를 정의\n","class TFGPT2Classifier(tf.keras.Model):\n","    def __init__(self, dir_path, num_class):\n","        super(TFGPT2Classifier, self).__init__()\n","        self.gpt2 = TFGPT2Model.from_pretrained(dir_path)\n","        self.num_class = num_class\n","\n","        self.dropout = tf.keras.layers.Dropout(self.gpt2.config.summary_first_dropout)\n","        self.classifier = tf.keras.layers.Dense(self.num_class, \n","                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=self.gpt2.config.initializer_range), name=\"classifier\")\n","        \n","    def call(self, inputs):\n","        outputs = self.gpt2(inputs)\n","        gpt_output =outputs[0][:, -1]\n","\n","        pooled_output = self.dropout(gpt_output)\n","        logits = self.classifier(pooled_output)\n","\n","        return logits"],"metadata":{"id":"qCpl3DJLt6Ec","executionInfo":{"status":"aborted","timestamp":1660108824712,"user_tz":-540,"elapsed":423,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 분류기 모델을 학습하는 방법은 책에 앞서 등장했던 BERT나 GPT1의 학습 방법과 동일하다고 함\n","# 먼저 분류기 모델을 생성하고 최적화 함수와 손실 함수, 평가에 활용할 정확도 함수를 구성해 model.compile을 실행하면\n","# 모델을 학습할 준비가 끝남\n","cls_model = TFGPT2Classifier(dir_path=BASE_MODEL_PATH, num_class=2)\n","\n","optimizer = tf.keras.optimizers.Adam(6.25e-5)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","cls_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"],"metadata":{"id":"AJsxZZoszPjS","executionInfo":{"status":"aborted","timestamp":1660108824713,"user_tz":-540,"elapsed":423,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습을 진행할 때는 GPU로 학습하는 것을 권장한다고 함(그래서 처음 코드 실행할 때부터 런타임:GPU로 해놓았음)\n","model_name = 'tf2_gpt2'\n","\n","earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=2)\n","\n","# 이부분 경로는 일단 그냥 구글드라이브의 data 모아놨던 곳으로 코드 바꿈\n","checkpoint_path = os.path.join(path, model_name, 'weights.h5')\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","if os.path.exists(checkpoint_dir):\n","    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","else: \n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","\n","cp_callback = ModelCheckpoint(\n","    checkpoint_path, \n","    monitor=\"val_accuracy\", \n","    verbose=1, \n","    save_best_only=True, \n","    save_weights_only=True, \n",")\n","history = cls_model.fit(\n","    train_data_sents, \n","    train_data_labels, \n","    epochs=2, # 임의로 정함\n","    batch_size=16, # 임의로 정함 \n","    callbacks=[earlystop_callback, cp_callback], \n",")"],"metadata":{"id":"m5yv9-AsB60d","executionInfo":{"status":"aborted","timestamp":1660108824713,"user_tz":-540,"elapsed":423,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["위에서 cls_model.fit() 실행 시 각 Epoch 당 약 25분 정도의 시간이 소요됨(런타임: GPU로 설정 기준)  \n","- 첫 번째 Epoch의 accuracy: 85.22%\n","- 두 번째 Epoch의 accuracy: 88.61%"],"metadata":{"id":"N9XlNJ67kbmo"}},{"cell_type":"code","source":["# 앞에서 numpy array로 변환 실패해서 오류 뜬게 결국 문제가 됨\n","# 그 이전 코드에서 maxlen을 특정 숫자로 설정해주니까 드디어 실행됨\n","\n","# accuracy와 loss를 그래프로 나타내기 위한 함수 정의\n","def plot_graphs(history, string):\n","    plt.plot(history.history[string])\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(string)\n","    plt.legend([string])\n","    plt.show()"],"metadata":{"id":"hl83zDJ-FtTT","executionInfo":{"status":"aborted","timestamp":1660108824714,"user_tz":-540,"elapsed":424,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_graphs(history, 'accuracy')"],"metadata":{"id":"TbJNRtwahqpO","executionInfo":{"status":"aborted","timestamp":1660108824715,"user_tz":-540,"elapsed":425,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_graphs(history, 'loss')"],"metadata":{"id":"wY_BhWIdZpSc","executionInfo":{"status":"aborted","timestamp":1660108824716,"user_tz":-540,"elapsed":21,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6-4. final_test_data로 모델의 성능 테스트하기"],"metadata":{"id":"K_1voRDyZwXh"}},{"cell_type":"code","source":["# 이제 test 데이터로 테스트를 진행\n","test_data_sents = []\n","test_data_labels = []\n","\n","for test_sent, test_label in test_data[['document', 'label']].values:\n","    test_tokenized_text = vocab[tokenizer(test_sent)] \n","    # 위 코드 역시 우측 부분이 책에는 clean_text(test_sent)로 되어있었으나 검색해보니\n","    # clean_text가 불필요한 문자 제거 그런거여서 이미 정제된 상태이므로 그냥 test_sent로 작성함\n","\n","    tokens = [vocab[vocab.bos_token]]\n","    tokens += pad_sequences([test_tokenized_text], \n","                            maxlen=28, \n","                            value=vocab[vocab.padding_token], \n","                            padding='post').tolist()[0]\n","    tokens += [vocab[vocab.eos_token]]\n","\n","    test_data_sents.append(tokens)\n","    test_data_labels.append(test_label)"],"metadata":{"id":"JXmhZ8F5ZpqX","executionInfo":{"status":"aborted","timestamp":1660108824716,"user_tz":-540,"elapsed":21,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data_sents = np.array(test_data_sents, dtype=np.int64)\n","test_data_labels = np.array(test_data_labels, dtype=np.int64)"],"metadata":{"id":"PJTe_1naZp5y","executionInfo":{"status":"aborted","timestamp":1660108824717,"user_tz":-540,"elapsed":22,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 다음 코드에서 load_weights에 대응하는 save-weights 코드가 없어 직접 짬\n","cls_model.save_weights(checkpoint_path)"],"metadata":{"id":"Bjg34hl8j9RC","executionInfo":{"status":"aborted","timestamp":1660108824717,"user_tz":-540,"elapsed":21,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cls_model.load_weights(checkpoint_path)\n","\n","results = cls_model.evaluate(test_data_sents, test_data_labels, batch_size=1024)"],"metadata":{"id":"dUi3VHGHavhR","executionInfo":{"status":"aborted","timestamp":1660108824720,"user_tz":-540,"elapsed":24,"user":{"displayName":"이강민","userId":"04405449783523250799"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["test_data에 모델을 테스트해본 결과 accuracy가 88.12%로 꽤 나쁘지 않은 성능을 보였음  \n","다른 KoBERT나 Bi-LSTM 모델의 결과와 비교해 본 뒤 가장 성능이 좋은 모델을 선택하면 될 것 같음"],"metadata":{"id":"iUxl_ufslHNe"}},{"cell_type":"markdown","source":["# END"],"metadata":{"id":"bBhlR9eulbfo"}}]}
